{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE: feature number annotation can be found in pos.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the each dataset and store to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/K1_dataset.txt\") as f:\n",
    "    K1_txt = f.read()\n",
    "\n",
    "with open(\"./data/K2_dataset.txt\") as f:\n",
    "    K2_txt = f.read()\n",
    "\n",
    "with open(\"./data/Q_dataset.txt\") as f:\n",
    "    Q_txt = f.read()\n",
    "\n",
    "df = pd.DataFrame([\n",
    "    [\"K1\", K1_txt], \n",
    "    [\"K2\", K2_txt],\n",
    "    [\"Q\", Q_txt]\n",
    "],\n",
    "columns=['author', 'message'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K1</td>\n",
       "      <td>Download\\n\\nSource\\n\\nPDF\\nActions\\n   Copy Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K2</td>\n",
       "      <td>\\n\\nWith the rapid growth of the information c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q</td>\n",
       "      <td>\\n\\nHowever, there are frequent situations whe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  author                                            message\n",
       "0     K1  Download\\n\\nSource\\n\\nPDF\\nActions\\n   Copy Pr...\n",
       "1     K2  \\n\\nWith the rapid growth of the information c...\n",
       "2      Q  \\n\\nHowever, there are frequent situations whe..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a list of tuples of (word, POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function returns a list of tuples of (word, PoS) from a document.\n",
    "'''\n",
    "def create_word_pos_list(message):\n",
    "    tokenized_txt = nltk.word_tokenize(message)\n",
    "    return nltk.pos_tag(tokenized_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(2,\"word_pos_list\",[ create_word_pos_list(message) for message in df['message']],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('However', 'RB'), (',', ','), ('there', 'EX')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['word_pos_list'][2][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mサンプル文字列\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "RED = '\\033[31m'\n",
    "GREEN = '\\033[32m'\n",
    "END = '\\033[0m'\n",
    "print(GREEN + \"サンプル文字列\" + END)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"In\".casefold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query_string):\n",
    "    query = query_string.split()\n",
    "    print(\"query : \", query)\n",
    "    for docId, document in enumerate(df['word_pos_list']):\n",
    "        for idx, (word, pos), in enumerate(document):\n",
    "            # print(f'(word, pos): {word}, {pos}')\n",
    "            if word.casefold() == query[0].casefold(): # undistinguith Upper or Lower case\n",
    "                # check the following words matche the sequence of words\n",
    "                foundFlg = True\n",
    "                # print(\"Following \", query[1:])\n",
    "\n",
    "                if len(query)>1:\n",
    "\n",
    "                    for i, query_following in enumerate(query[1:]):\n",
    "                        try:\n",
    "                            word_following = document[idx+1+i][0] # follwoing word in the document\n",
    "                            pos_following = document[idx+1+i][1] # follwoing pos in the document\n",
    "                        except: # if cannot access the index\n",
    "                            break\n",
    "                        if query_following.casefold() == word_following.casefold() or query_following == pos_following:\n",
    "                            continue\n",
    "                        foundFlg = False\n",
    "                    \n",
    "                if foundFlg is True:\n",
    "                    if docId == 0:\n",
    "                        print(\"K1:  \", end=\"\")\n",
    "                    elif docId == 1:\n",
    "                        print(\"K2:  \", end=\"\")\n",
    "                    elif docId == 2:\n",
    "                        print(\"Q :  \", end=\"\")\n",
    "\n",
    "\n",
    "                    # 前後6 文字　出力\n",
    "                    pid = idx - 6\n",
    "                    for _ in range(6):\n",
    "                        if pid < 0:\n",
    "                            print(\"    \", end=\"\")\n",
    "                        elif pid >= 0:\n",
    "                            print(document[pid][0], end=\" \")\n",
    "                        pid += 1\n",
    "\n",
    "                    print(GREEN + word + END, end=\" \")\n",
    "\n",
    "                    sid = idx + 1\n",
    "                    for _ in range(6):\n",
    "                        if sid < len(document):\n",
    "                            print(document[sid][0], end=\" \")\n",
    "                        else:\n",
    "                            print(\"    \", end=\"\")\n",
    "                        sid += 1\n",
    "\n",
    "                    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query :  ['to', 'VB']\n",
      "K1:  other authors . Our idea is \u001b[32mto\u001b[0m investigate how computational models can enhance \n",
      "K1:  metaphors hidden in the pieces thought \u001b[32mto\u001b[0m be for children rather lies in \n",
      "K1:  science and artificial intelligence may contribute \u001b[32mto\u001b[0m musicology research on music style identification \n",
      "K1:  . In this study we try \u001b[32mto\u001b[0m discover appropriate formal models that would \n",
      "K1:  require intensive cross-disciplinary efforts so as \u001b[32mto\u001b[0m bridge the communities working in different \n",
      "K1:  many rules but giving some freedom \u001b[32mto\u001b[0m support the individual styles of composers \n",
      "K1:  similarity estimation [ 13 ] seem \u001b[32mto\u001b[0m be more adequate to the problem \n",
      "K1:  harmonic equivalence may not be enough \u001b[32mto\u001b[0m recognize the melody , as demonstrated \n",
      "K1:  SPEAC-analysis can be a promising approach \u001b[32mto\u001b[0m model music style similarity through SPEAC \n",
      "K1:  that the main challenge is not \u001b[32mto\u001b[0m teach AI to create art objects \n",
      "K1:  challenge is not to teach AI \u001b[32mto\u001b[0m create art objects , but to \n",
      "K1:  to create art objects , but \u001b[32mto\u001b[0m be able to help us in \n",
      "K1:  objects , but to be able \u001b[32mto\u001b[0m help us in perceiving objects created \n",
      "K1:  the composer , a natural desire \u001b[32mto\u001b[0m overcome the temporary barrier and directly \n",
      "K1:  hypothesis claiming that Tchaikovsky probably preferred \u001b[32mto\u001b[0m hide some metaphors so that they \n",
      "K1:  musicology , we could not expect \u001b[32mto\u001b[0m find a final answer ( and \n",
      "K1:  ) . Instead , a possibility \u001b[32mto\u001b[0m incorporate formal computational approaches into informal \n",
      "K2:  approaches to reducing energy consumption is \u001b[32mto\u001b[0m increase the ambient temperature , thus \n",
      "K2:  [ 3 ] . Therefore , \u001b[32mto\u001b[0m increase energy efficiency in datacentres , \n",
      "K2:  datacentres , one effective solution is \u001b[32mto\u001b[0m raise the operating temperature , thus \n",
      "K2:  ambient temperatures is another important aspect \u001b[32mto\u001b[0m be investigated . Recently , several \n",
      "K2:  , it can also be used \u001b[32mto\u001b[0m implement reliable and ultra-fast interconnects in \n",
      "K2:  hybrid ( SPH ) modulator . \u001b[32mTo\u001b[0m fabricate the SPH modulator , we \n",
      "K2:  backbone with a high loading density \u001b[32mto\u001b[0m realize the second-order nonlinear effect , \n",
      "K2:  polymer , dialysis purification is performed \u001b[32mto\u001b[0m remove polymers with low molecular weights \n",
      "K2:  the demands for industrial applications due \u001b[32mto\u001b[0m incomplete thermal reversibility with molecular disordering \n",
      "K2:  synthesized EO polymer is then used \u001b[32mto\u001b[0m fabricate the SPH modulator , which \n",
      "K2:  µm-thick EO polymer layer is structured \u001b[32mto\u001b[0m be sandwiched between two cladding layers \n",
      "K2:  deposited on the MZI arms . \u001b[32mTo\u001b[0m achieve a large EO bandwidth , \n",
      "K2:  width of the electrodes are designed \u001b[32mto\u001b[0m be 3 μm and 16 μm \n",
      "K2:  . More importantly , in contrast \u001b[32mto\u001b[0m crystalline and amorphous material modulators , \n",
      "K2:  to negligible velocity mismatching between them \u001b[32mto\u001b[0m enable high-speed and broadband operations of \n",
      "K2:  bandwidth of the device is presumed \u001b[32mto\u001b[0m be over 70 GHz . To \n",
      "K2:  to be over 70 GHz . \u001b[32mTo\u001b[0m ensure a high EO efficiency , \n",
      "K2:  Multilevel modulation is another effective method \u001b[32mto\u001b[0m increase the operating rate of the \n",
      "K2:  of 92 GSa s-1 is deployed \u001b[32mto\u001b[0m drive the SPH modulator . Optical \n",
      "K2:  , it would be more effective \u001b[32mto\u001b[0m measure dynamic properties like BER or \n",
      "K2:  °C ) is ~140 °C . \u001b[32mTo\u001b[0m validate the high-speed functionality of the \n",
      "K2:  footprint but shows a strong sensitivity \u001b[32mto\u001b[0m ambient temperature fluctuations especially on a \n",
      "K2:  . Most of the proposed approaches \u001b[32mto\u001b[0m overcome the thermal instability issue in \n",
      "K2:  signal quality from the devices . \u001b[32mTo\u001b[0m compare the EO activity of these \n",
      "K2:  the integration with CMOS circuits . \u001b[32mTo\u001b[0m improve the energy efficiency of the \n",
      "K2:  transceivers , another effective approach is \u001b[32mto\u001b[0m raise the ambient temperature of the \n",
      "K2:  modulator could provide an effective solution \u001b[32mto\u001b[0m ensure high throughput and reliable network \n",
      "K2:  our device could be further optimized \u001b[32mto\u001b[0m realize a more compact footprint , \n",
      "K2:  of future ultra-dense high-speed parallelized interconnects \u001b[32mto\u001b[0m facilitate dense modulator arrays [ 55 \n",
      "K2:  waveguide core as a cladding material \u001b[32mto\u001b[0m counterbalance the core ’ s thermo-optic \n",
      "K2:  °C for 24 hours under vacuum \u001b[32mto\u001b[0m form a 1 µm-thick slab . \n",
      "K2:  EO polymer as a top cladding \u001b[32mto\u001b[0m protect the device during the poling \n",
      "K2:  vacuum deposition and electroplating techniques . \u001b[32mTo\u001b[0m activate the second-order nonlinear effect in \n",
      "K2:  around Tg of the EO polymer \u001b[32mto\u001b[0m align chromophores . After cooling down \n",
      "K2:  the transmission line impedance is designed \u001b[32mto\u001b[0m be matched to the 50 Ω \n",
      "K2:  reduced . Device bandwidth characterization . \u001b[32mTo\u001b[0m confirm the broadband operation of the \n",
      "K2:  10 MHz~70 GHz ) is used \u001b[32mto\u001b[0m characterize the frequency response of the \n",
      "K2:  , and Fig . 3a . \u001b[32mTo\u001b[0m generate OOK signals , high-speed electrical \n",
      "K2:  , raised cosine filtering and down-sampling \u001b[32mto\u001b[0m form the driving electric signals . \n",
      "K2:  form the driving electric signals . \u001b[32mTo\u001b[0m detect the synthesized OOK and PAM4 \n",
      "K2:  ( TEC ) element installed , \u001b[32mto\u001b[0m alter the operating temperature from 25 \n",
      "K2:  . On the other hand , \u001b[32mto\u001b[0m perform the high-temperature storage test , \n",
      "K2:  and then optically and electrically activated \u001b[32mto\u001b[0m verify its high-speed functionality at room \n",
      "Q :  the paper and outlines the aspects \u001b[32mto\u001b[0m be considered in future work . \n",
      "Q :  , poguntke2020notimodes } or enabling them \u001b[32mto\u001b[0m manage their activity-related choices , for \n",
      "Q :  } . Such proactive services help \u001b[32mto\u001b[0m overcome the limitations of human decision-making \n",
      "Q :  the naturally limited capabilities of individuals \u001b[32mto\u001b[0m memorize , store or organize information~\\cite \n",
      "Q :  . Notifications give the common approach \u001b[32mto\u001b[0m link the current context to a \n",
      "Q :  a description of a deferred action \u001b[32mto\u001b[0m be implemented later . Here are \n",
      "Q :  the paper and outlines the aspects \u001b[32mto\u001b[0m be considered in future work . \n",
      "Q :  [ 21,22 ] or enabling them \u001b[32mto\u001b[0m manage their activity-related choices , for \n",
      "Q :  . Such proac- tive services help \u001b[32mto\u001b[0m overcome the limitations of human decision-making \n",
      "Q :  the naturally limited capabilities of individuals \u001b[32mto\u001b[0m memorize , store or organize informa- \n",
      "Q :  . Notifications give the common approach \u001b[32mto\u001b[0m link the current context to a \n",
      "Q :  a description of a deferred action \u001b[32mto\u001b[0m be implemented later . 3 . \n",
      "Q :  so urgent that one must go \u001b[32mto\u001b[0m find it immediately . Instead , \n",
      "Q :  Instead , it might be helpful \u001b[32mto\u001b[0m be reminded while the person in \n",
      "Q :  but a reminder could be helpful \u001b[32mto\u001b[0m describe a kind of deferred activity \n",
      "Q :  theatre or cinema lover would like \u001b[32mto\u001b[0m watch a particular performance ( maybe \n",
      "Q :  . 4 . A householder needs \u001b[32mto\u001b[0m do some housework , where specific \n",
      "Q :  elicitation . Software prototyping helps us \u001b[32mto\u001b[0m refine the requirements and revisit the \n",
      "Q :  in Figure 5 ) providing grounds \u001b[32mto\u001b[0m discover major entities to be modeled \n",
      "Q :  providing grounds to discover major entities \u001b[32mto\u001b[0m be modeled in the system and \n",
      "Q :  set by the user are assumed \u001b[32mto\u001b[0m belong to the following major classes \n",
      "Q :  . 1 . Active reminders are \u001b[32mto\u001b[0m be configured by the user and \n",
      "Q :  setup . The templates are assumed \u001b[32mto\u001b[0m be configured partially , or suggested \n",
      "Q :  the cases if the user wishes \u001b[32mto\u001b[0m save the previously configured reminders for \n",
      "Q :  Figure 6 shows the major scenarios \u001b[32mto\u001b[0m be supported by this system . \n",
      "Q :  reminder describing major events and actions \u001b[32mto\u001b[0m create a reminder , manage the \n",
      "Q :  . Piloting Prototypes : Lessons Learned \u001b[32mTo\u001b[0m improve our understanding of the project \n",
      "Q :  of the project goals and challenges \u001b[32mto\u001b[0m resolve , we experi- mented with \n",
      "Q :  of situational planning scenario implementation is \u001b[32mto\u001b[0m assure that relevant notifications are issued \n",
      "Q :  in connection to specific locations . \u001b[32mTo\u001b[0m achieve this , location-based services such \n",
      "Q :  interest ) and enable registered applications \u001b[32mto\u001b[0m trigger responses when a mobile device \n",
      "Q :  issue : using the geometry-based distancing \u001b[32mto\u001b[0m decide on notification upon entering the \n",
      "Q :  . Therefore , it is important \u001b[32mto\u001b[0m elicit a number of aspects to \n",
      "Q :  to elicit a number of aspects \u001b[32mto\u001b[0m be taken into the consideration while \n",
      "Q :  may affect user ’ s wish \u001b[32mto\u001b[0m proceed with the suggested deferred activity \n",
      "Q :  tion could make a suggestion hard \u001b[32mto\u001b[0m follow . 4 . Using programmed \n",
      "Q :  reminded activity to a regular plan \u001b[32mto\u001b[0m be included in the calendar or \n",
      "Q :  added voice input and cloud sync \u001b[32mto\u001b[0m make it easier to use . \n",
      "Q :  cloud sync to make it easier \u001b[32mto\u001b[0m use . For location-based reminders , \n",
      "Q :  ’ s geofence and cloud services \u001b[32mto\u001b[0m synchronize the geofence coordinates created in \n",
      "Q :  The following third-party services are shown \u001b[32mto\u001b[0m be helpful for developing a prototype \n",
      "Q :  Recognition – The component is used \u001b[32mto\u001b[0m recognize short audio and convert into \n",
      "Q :  in backing-up the configured reminder information \u001b[32mto\u001b[0m ensure that users can change or \n",
      "Q :  that the developer does not need \u001b[32mto\u001b[0m develop a separate server-side program . \n",
      "Q :  . However , the user needs \u001b[32mto\u001b[0m be registered with the cloud service \n",
      "Q :  real world , when people tend \u001b[32mto\u001b[0m create “ activity representations that are \n",
      "Q :  are simple , yet flexible enough \u001b[32mto\u001b[0m accommodate different levels of rigidity ” \n",
      "Q :  number of issues requiring further efforts \u001b[32mto\u001b[0m move the project towards its practical \n",
      "Q :  and activity organizers ; • Possibilities \u001b[32mto\u001b[0m apply knowledge-based recommendation and NLP algorithms \n",
      "Q :  recommendation and NLP algorithms so that \u001b[32mto\u001b[0m identify and suggest the suitable scenario \n",
      "Q :  involve sufficient arguable experi- mental results \u001b[32mto\u001b[0m contrast the approach against the existing \n"
     ]
    }
   ],
   "source": [
    "search(\"to VB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query :  ['how', 'JJ', 'NNS']\n",
      "K1:  . Our idea is to investigate \u001b[32mhow\u001b[0m computational models can enhance musicology research \n"
     ]
    }
   ],
   "source": [
    "search(\"how JJ NNS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query :  ['services', 'NN']\n",
      "Q :  { hasan2013understanding } . Such proactive \u001b[32mservices\u001b[0m help to overcome the limitations of \n",
      "Q :  23 ] . Such proac- tive \u001b[32mservices\u001b[0m help to overcome the limitations of \n"
     ]
    }
   ],
   "source": [
    "search(\"services NN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## suspect の前処理\n",
    " - 全てのデータせっとに現れるPOSパターンのリストを作成\n",
    " - 同時にそれぞれのデータセットでカウントしていく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 2\n",
    "def count_pos_patterns(documents):\n",
    "    width = WINDOW_SIZE\n",
    "    pos_patterns = []\n",
    "    pos_vectors = [[] for _ in range(len(documents))]\n",
    "    for docId, document in enumerate(documents):\n",
    "        len_doc = len(document)\n",
    "        for i in range(len_doc - (width-1)):\n",
    "            key_str = \"\"\n",
    "            key_str += document[i][0] # word\n",
    "\n",
    "            for j in range(1, width):\n",
    "                key_str += \" \" + document[i+j][1] # POS\n",
    "\n",
    "            if key_str not in pos_patterns:\n",
    "                pos_patterns.append(key_str)\n",
    "                # パターンが現れたドキュメント -> 1 , それ以外　-> 0\n",
    "                for i in range(len(pos_vectors)): # loop for K1, K2, Q\n",
    "                    if i == docId:\n",
    "                        pos_vectors[i].append(1)\n",
    "                    else:\n",
    "                        pos_vectors[i].append(0)\n",
    "\n",
    "            else: \n",
    "                idx = pos_patterns.index(key_str)\n",
    "                pos_vectors[docId][idx] += 1\n",
    "\n",
    "    return (pos_patterns, pos_vectors)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>message</th>\n",
       "      <th>word_pos_list</th>\n",
       "      <th>pos_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K1</td>\n",
       "      <td>Download\\n\\nSource\\n\\nPDF\\nActions\\n   Copy Pr...</td>\n",
       "      <td>[(Download, NNP), (Source, NNP), (PDF, NNP), (...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K2</td>\n",
       "      <td>\\n\\nWith the rapid growth of the information c...</td>\n",
       "      <td>[(With, IN), (the, DT), (rapid, JJ), (growth, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q</td>\n",
       "      <td>\\n\\nHowever, there are frequent situations whe...</td>\n",
       "      <td>[(However, RB), (,, ,), (there, EX), (are, VBP...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  author                                            message  \\\n",
       "0     K1  Download\\n\\nSource\\n\\nPDF\\nActions\\n   Copy Pr...   \n",
       "1     K2  \\n\\nWith the rapid growth of the information c...   \n",
       "2      Q  \\n\\nHowever, there are frequent situations whe...   \n",
       "\n",
       "                                       word_pos_list  \\\n",
       "0  [(Download, NNP), (Source, NNP), (PDF, NNP), (...   \n",
       "1  [(With, IN), (the, DT), (rapid, JJ), (growth, ...   \n",
       "2  [(However, RB), (,, ,), (there, EX), (are, VBP...   \n",
       "\n",
       "                                             pos_vec  \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_patterns, pos_vectors = count_pos_patterns(df['word_pos_list'])\n",
    "df['pos_vec'] = pos_vectors\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the NN'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 2\n",
    "max_idx = pos_vectors[i].index(max(pos_vectors[i]))\n",
    "pos_patterns[max_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start からend までのIDの配列を返す\n",
    "def extract_features(freq_vector, start=0, end=20):\n",
    "\n",
    "    setX = set(freq_vector) # 最大値を順に取り出すため set を作成\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    result = []\n",
    "\n",
    "    while count<end:\n",
    "        try:\n",
    "            max_value = max(setX)\n",
    "        except ValueError:\n",
    "            return result\n",
    "\n",
    "        max_index = freq_vector.index(max_value)\n",
    "        # max_word = words[max_index]\n",
    "\n",
    "        setX.remove(max_value)\n",
    "\n",
    "        if count>= start:\n",
    "            result.append(max_index)\n",
    "        count += 1\n",
    "\n",
    "\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the score of how many types of pattern are appered in both vectors?\n",
    "def get_similarity(feature_vector1,feature_vector2): \n",
    "    return len(set(feature_vector1) & set(feature_vector2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "K1_features = extract_features(pos_vectors[0], 0, 60)\n",
    "K2_features = extract_features(pos_vectors[1], 0, 60)\n",
    "Q_features = extract_features(pos_vectors[2], 0, 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similarity(K1_features, Q_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(Q_df,K_df):\n",
    "    start = 0\n",
    "    end = 20\n",
    "    suspected = [author for author in K_df['author'] ]\n",
    "    while(len(suspected) > 1):\n",
    "        print(\"Suspected : \", end=\"\")\n",
    "        print(set(suspected))\n",
    "        Q_features = extract_features(Q_df['pos_vec'], start, end)\n",
    "        similarityWithQ = {}\n",
    "\n",
    "        for author, reference_vector in (K_df['author'], K_df['pos_vec']):\n",
    "            if author in suspected: #\n",
    "                feature_vector = extract_features(reference_vector,start, end)\n",
    "                score = get_similarity(feature_vector,Q_features)\n",
    "                similarityWithQ[author]=score\n",
    "\n",
    "        # innocent_list に含まれない著者の中から1人を選ぶ\n",
    "\n",
    "        innocent = min(similarityWithQ, key=similarityWithQ.get)\n",
    "        if input(f'Do you want to rule out {innocent} in top {end} patterns ? (y/n) ') == 'y':\n",
    "            suspected.remove(innocent)\n",
    "        end += 20\n",
    "    return suspected[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suspected : {'K2', 'K1'}\n",
      "Suspected : {'K2', 'K1'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'K2'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict(df[:][1])\n",
    "K_df = df.loc[0:1]\n",
    "Q_df = df.loc[2]\n",
    "predict(Q_df, K_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "expsystem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
